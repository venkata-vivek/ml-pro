{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58fab4bb-231e-48cf-8ed4-fc15a1b22845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<h4 style=\"font-variant-caps: small-caps;font-size:35pt;\">Databricks-ML-professional-S01b-Experiment-Tracking</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e02262c-d60e-40aa-a4e9-39b9743b00b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:black;border-radius:5px;border-top:1px solid'></div>\n",
    "<br/>\n",
    "<p>This Notebook adds information related to the following requirements:</p><br/>\n",
    "<b>Experiment Tracking:</b>\n",
    "<ul>\n",
    "<li>Manually log parameters, models, and evaluation metrics using MLflow</li>\n",
    "<li>Programmatically access and use data, metadata, and models from MLflow experiments</li>\n",
    "</ul>\n",
    "<br/>\n",
    "<p><b>Download this notebook at format ipynb <a href=\"Databricks-ML-professional-S01b-Experiment-Tracking.ipynb\">here</a>.</b></p>\n",
    "<br/>\n",
    "<div style='background-color:black;border-radius:5px;border-top:1px solid'></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5f6d0da-1d81-4fa0-9770-a9e4d6863534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">1. Import libraries</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2d2e59-7426-4d5f-8d97-3dcff6e5151d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#\n",
    "from pyspark.sql.functions import *\n",
    "#\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "#\n",
    "import mlflow\n",
    "#\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e27ecd-7d1c-49ea-93bf-e6056ef8f623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"mlflow\").setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa08db2c-a856-4c86-81fe-9a8b7322cd6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">2. Load dataset, convert to Spark DataFrame</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b64ff08-1603-4d0c-bc4e-19c0094c3b9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tips_df = sns.load_dataset(\"tips\")\n",
    "#\n",
    "tips_sdf = spark.createDataFrame(tips_df)\n",
    "#\n",
    "display(tips_sdf.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d00502-ebc9-47fd-8026-2f93efa06258",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(tips_sdf.filter(\"size is null\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b595b34-0633-4f66-9ca0-6067f4cc0716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">3. Prepare data</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "453316e6-0dc3-41b0-9730-27c39ed9bdf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p>Some transformations are done to prepare dataset to be used in training a ML model.</p>\n",
    "<table border style='border-collapse: collapse;'>\n",
    "<tr style=\"background-color:#EDEDED\">\n",
    "    <th>column name</th>\n",
    "    <th>comment</th>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>tip</code></td>\n",
    "    <td><b style='color:orangered'>target</b> to predict. Contains numeric</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>total_bill</code></td>\n",
    "    <td>numeric column to keep as is</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>sex</code></td>\n",
    "    <td>Contains <code>Female</code> and <code>Male</code> converted to <code>0</code> and <code>1</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>smoker</code></td>\n",
    "    <td>Contains <code>yes</code> and <code>no</code> converted to <code>0</code> and <code>1</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>time</code></td>\n",
    "    <td>Contains <code>Dinner</code> and <code>Lunch</code> converted to <code>0</code> and <code>1</code></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>day</code></td>\n",
    "    <td>categorical column to <b>One Hot Encode</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><code>size</code></td>\n",
    "    <td>categorical column to <b>One Hot Encode</b></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c6fbbf-0a08-4fee-8ad7-abdf5a0f9ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tips_sdf = tips_sdf.selectExpr(\"total_bill\",\n",
    "                               \"tip\",\n",
    "                               \"case when sex = 'Female' then 1 else 0 end as sex\",\n",
    "                               \"case when smoker = 'yes' then 1 else 0 end as smoker\",\n",
    "                               \"case when time = 'Dinner' then 1 else 0 end as time\",\n",
    "                               \"day\",\n",
    "                               \"size\")\n",
    "#\n",
    "train_df, test_df = tips_sdf.randomSplit([.8, .2])\n",
    "#\n",
    "ohe_cols = [\"size\", \"day\"]\n",
    "num_cols = [\"total_bill\", \"sex\", \"smoker\", \"time\"]\n",
    "target_col = \"tip\"\n",
    "#\n",
    "string_indexer = StringIndexer(inputCols=ohe_cols, outputCols=[c+\"_index\" for c in ohe_cols], handleInvalid=\"skip\")\n",
    "#\n",
    "ohe = OneHotEncoder()\n",
    "ohe.setInputCols([c+\"_index\" for c in ohe_cols])\n",
    "ohe.setOutputCols([c+\"_ohe\" for c in ohe_cols])\n",
    "#\n",
    "assembler_inputs = [c+\"_ohe\" for c in ohe_cols] + num_cols\n",
    "vec_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "910af898-da90-4e26-a856-cdb4b902e101",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">4. Evaluator and model</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06212c8c-e7bf-45e7-827f-fd3fcad64486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gbt =       GBTRegressor(featuresCol=\"features\", labelCol=target_col, maxIter=5)\n",
    "evaluator = RegressionEvaluator(labelCol=target_col, predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd1fc5a1-c77d-45e4-88b2-d2861900b3e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<a id=\"manuallylog\"></a>\n",
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">5. Manually log parameters, models, and evaluation metrics using MLflow</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a1d573-d054-48bb-864a-fb9eab2efaa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"GBT-Regressor\"\n",
    "#\n",
    "with mlflow.start_run(run_name=\"Tip-run\") as run:\n",
    "    #\n",
    "    # define pipeline stages according to model\n",
    "    stages = [string_indexer, ohe, vec_assembler, gbt]\n",
    "    #\n",
    "    # set pipeline\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    #\n",
    "    # fit pipeline to train set\n",
    "    model = pipeline.fit(train_df)\n",
    "    #\n",
    "    # manually log model to mlflow\n",
    "    mlflow.spark.log_model(model, model_name)\n",
    "    #\n",
    "    # manually log parameter to mlflow\n",
    "    mlflow.log_param(\"maxIter\", 5)\n",
    "    #\n",
    "    # predict test set\n",
    "    pred_df = model.transform(test_df)\n",
    "    #\n",
    "    # evaluate prediction\n",
    "    rmse = evaluator.evaluate(pred_df)\n",
    "    #\n",
    "    # manually log metric to mlflow\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7c1ad7c-c381-4758-bb59-5114ba6f0ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<a id=\"programmaticallyaccess\"></a>\n",
    "<div style='background-color:rgba(30, 144, 255, 0.1);border-radius:5px;padding:2px;'>\n",
    "<span style=\"font-variant-caps: small-caps;font-weight:700\">6. Programmatically access and use data, metadata, and models from MLflow experiments</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89edcb39-0b90-44ca-b6fd-5af69c3115a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p>This can be done in different ways. One of them is to access it programmaticaly with the function <code>mlflow.search_runs</code> which results in a Pandas dataframe containing all useful information for all runs in the current experiment <i>(by default, the current experiment has the name of the current notebook)</i>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5839d28-4117-400d-9a8c-d7fa5fbd0665",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.search_runs().drop(['tags.mlflow.databricks.workspaceURL',\n",
    "                           'tags.mlflow.databricks.notebookPath',\n",
    "                           'tags.mlflow.source.name',\n",
    "                           'tags.mlflow.user'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f04a8cf6-a501-4e11-a7af-66b9b9bd6744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p>Using Pandas syntax information can be filtered on what is needed:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d945c5-a93c-4f84-a01b-341d71e9f980",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.search_runs()[[\"tags.mlflow.runName\", \"run_id\", \"params.maxIter\", \"metrics.rmse\"]].sort_values(by=['metrics.rmse'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ea640ea-2ab2-46f6-b53f-a440ef888681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p>A <b>SQL filter</b> can also be applied directly in the <code>mlflow.search_run()</code> function by using its <code>filter_string</code> parameter. This is particularly useful when there are many runs:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9844f927-34d9-4ffc-a1f7-c8c17bafc6bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.search_runs(filter_string=\"tags.mlflow.runName like '%Tip%' and metrics.rmse<=1.5\")[[\"tags.mlflow.runName\", \"run_id\", \"params.maxIter\", \"metrics.rmse\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de6aca3d-c7f8-4d16-881b-df28551dc63e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p>With this, let's load the best model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37c9d5a-6eb0-4eee-891f-d547ff1b08b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bestModelRunId = mlflow.search_runs().sort_values(by=['metrics.rmse'], ascending=True).head(1)[\"run_id\"].values[0]\n",
    "#\n",
    "best_model_path = f\"runs:/{bestModelRunId}/{model_name}\"\n",
    "print(f\"Best model path is: {best_model_path}\")\n",
    "#\n",
    "loaded_model = mlflow.spark.load_model(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75cd5545-72e8-4678-b590-48a52a6e19c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(loaded_model.transform(test_df).select(\"tip\", \"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67f74bab-3bc1-46ec-a68e-de198cc7b1c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://i.ibb.co/xSdfvyD/mlflow3.png\"/>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 121806328486209,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "Databricks-ML-professional-S01b-Experiment-Tracking",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
